<!DOCTYPE html>
<html lang="en-US">
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2024-04-03T12:40:43+02:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body>
<article class="assemblage assemblage-like"><h6 class="heading"><span class="title">evaluation of the deformation gradient (linear transformations).</span></h6>
<p>In the case of Transformation 1 already discussed above, we make explicit the dependence of the individual components of \(\vec{x}\) on the components of \(\vec{X}\text{:}\)</p>
<div xmlns:svg="http://www.w3.org/2000/svg" class="displaymath">
\begin{align*}
x_1 \amp = \func{\chi_1}{X_1, X_2} = -X_2\,,\\
x_2 \amp = \func{\chi_2}{X_1, X_2} = X_1\,.
\end{align*}
</div>
<p class="continuation">From which the following partial derivatives are obtained</p>
<div xmlns:svg="http://www.w3.org/2000/svg" class="displaymath">
\begin{align*}
\regulardiff{\chi_1}{X_1} = 0\,,\amp\quad \regulardiff{\chi_1}{X_2} = -1\,,\\
\regulardiff{\chi_2}{X_1} = 1\,,\amp\quad \regulardiff{\chi_2}{X_2} = 0
\end{align*}
</div>
<p class="continuation">and therefore the deformation gradient</p>
<div xmlns:svg="http://www.w3.org/2000/svg" class="displaymath">
\begin{equation*}
\mat{F} =
\left[\begin{array}{cc} \regulardiff{\chi_1}{X_1} \amp \regulardiff{\chi_1}{X_2} \\ \regulardiff{\chi_2}{X_1}  \amp \regulardiff{\chi_2}{X_2}  \end{array}\right] =
\left[\begin{array}{cc} 0 \amp -1 \\ 1  \amp 0  \end{array}\right]
\end{equation*}
</div>
<p class="continuation">The fact that in this case we obtain a constant gradient equal to the matrix \(\mat{M_{\chi}}\) associated with the transformation is not accidental but depends on the linearity of the transformation under consideration: inevitably, its own linearization coincides with the given transformation. A similar result would also be obtained for the other linear transformations considered in the previous examples.</p></article><span class="incontext"><a href="gradient_sec_strain_chap_en.html#assemblage-5">in-context</a></span>
</body>
</html>
